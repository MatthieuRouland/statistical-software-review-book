#  (PART) Introduction {-}

#  Overview of the Project and of this Book {#overview}

This book documents rOpenSci's project to expand peer review to include
explicitly statistic software. It is intended to aid both software developers
wishing to have their software reviewed under the newly expanded system, and
reviewers tasked with reviewing submissions. A third aim of the project, and
of this documentation, is to serve as a blueprint for future adoption and
adaptation in other areas, including other computer languages.

This chapter summarises overall project aims, the scope of statistical software
we are currently able to consider, and provides a brief overview of the
structure and purpose of this book. The book should be considered an extension
of rOpenSci's guide to software [Development, Maintenance, and Peer
Review](https://devguide.ropensci.org/) (the "*Dev Guide*"). The guidelines and
expectations for software as presented in the *Dev Guide* also apply to
statistical software under the newly expanded system, with this document
describing additional guides and expectations for explicitly statistical
software. The *Dev Guide* ought thus be considered essential reading prior to
the current book.

The present chapter provides a brief overview of the entire book, and consists
of the following sections:

- **[Motivation: Why a separate system for statistical
  software?](#motivation)** in which we explain the necessity and advantages of
  having statistical software developed according to concretes sets of explicit
  standards.

- **[Scope of Statistical Software Review](#scope)** in which we summarise our
  working definition of "statistical software", and the scope of software
  currently able to be considered under the project.

- **[Standards for Statistical Software](#standards)** in which we briefly
  describe the sets of standards to which statistical software will be expected
  to adhere.

- **[Assessment and Peer Review Processes](#process)** in which we describe how
  submitting authors will be expected to assess their software prior to
  submission, and how reviewers will be expected to assess submissions.

- **[Outcomes](#outcomes)** in which we describe outcomes of our review
  process, particular what submitting software developers can expect from our
  review process.


## Project Motivation

The official description of R declares it to be a ["software environment for
statistical computing and graphics"](https://www.r-project.org/), yet rOpenSci
previously deemed explicitly statistical packages out of scope, owing among
other factors to the perceived difficulty of devising an appropriate system for
assessment and review. R is nevertheless an explicitly *statistical* computing
environment, and so rOpenSci developed this project to expand our peer review
system to include statistical software. 

In doing so, the project also offered an opportunity to reconsider and
potentially improve aspects of rOpenSci's current system for peer review, which
has operated for five years, and has reviewed over >200 packages, primarily in
areas of data life cycle management. The form of these packages continues to be
strongly influenced by the *Dev Guide*, which presents sets of
["guidelines"](https://devguide.ropensci.org/building.html) which packages are
expected to "meet". These guidelines are nevertheless necessarily general, and
were largely developed in ongoing response to successive developments in
technology to support software development, such as continuous integration
services. Although our *Dev Guide* effectively provides a set of "standards" to
which software is expected to adhere, the alignment of software to these
standards it itself not necessarily systematic, and in particular there is no
direct way to ascertain the standards to which a given piece of software
adheres, and those from which it may diverge.

The present project aims to develop a more systematic alignment of software
with standards, one which will enable automated and ongoing identification of
those standards with which a given piece of software complies. The following
sets of standards for statistical software are thus far more extensive that our
previous "guidelines", and aim to provide ongoing assurance for users of the
standard of software accepted within our system, including systematic
identification of ways by which software may diverge from standards, and
explanations of why.

Such assurance is important in many areas of scientific research, notably
including those subject to regulation such as pharmaceutical trials. Software
used in such trials must be "validated", generally through a process of
identifying any risks associated with using that software. In such contexts,
our system will foster confidence in the use of software assessed according to
our standards. For developers, the system will provide a "badge" able to be
used to identify and publicise the assessment of their software as meeting the
standards set by our system.



## Scope of Statistical Software Review

The present project represents a direct expansion of rOpenSci's current
[scope](https://devguide.ropensci.org/policies.html#aims-and-scope) to include
specifically statistical software, while retaining the restriction to software
in the form of R packages. Empirical analyses described in Appendix A.2 were
devised to identify sub-domains within statistical software, from which we have
currently developed standards for the following categories:

1. [Bayesian and Monte Carlo Routines](#scope-category-bayesian)
2. [Regression and Supervised Learning](#scope-category-supervised)
3. [Dimensionality Reduction, Clustering, and Unsupervised Learning](#scope-category-unsupervised)
4. [Exploratory Data Analysis (EDA) and Summary Statistics](#scope-category-EDA)
5. [Time Series Analyses](#scope-category-time)
6. [Machine Learning](#scope-category-ML)
7. [Spatial Analyses](#scope-category-spatial)

These categories provide our working definition of statistical software able to
be considered for submission to our system as any software described by one of
more of the categories. Each of these categories is represented by a set of
standards, as briefly described in the following sub-section. We anticipate
that submissions will commonly fit into, or be described by, multiple
categories, and the standards have also been devised to be as inter-compatible
as possible. Moreover, alignment with specific categories may not always be
straightforward, and we anticipate some submissions requiring negotiation
between developers and editors to identify appropriate categories prior to
submission.

We also intend to expand the system to include the additional four categories
of:

1. [Wrapper Packages](#scope-category-wrapper)
2. [Network Analysis Software](#scope-category-networks)
3. [Probability Distributions](#scope-category-distributions)
4. [Workflow Support](#scope-category-workflow)

While software in these latter four categories is beyond the scope of current
standards, we invite any software developers interested in submitting software
within one or more of these categories to contact us directly to enquire about
the status of associated standards, and the possibility of submitting. Finally,
we anticipate our sets of standards to expand further over time, and openly
invite any form of discussion on the possibility of expanding our definition to
include additional categories.


## Standards for Statistical Software

One of the primary outputs of the project to develop our system to peer-review
statistical software has been a detailed suite of standards, both *General
Standards* applicable to all statistical software to be considered under our
system, along with category-specific standards for each of the aforementioned
categories. These standards have been developed in explicit acknowledgement of
the sentiments of Colin Gillespie, expressed in his keynote speech at the
[European R Users Meeting
2020](https://2020.erum.io/program/keynotes-invited-speakers/):

> Standards are good<br>
> Standards should be strict<br>
> No-one reads standards

The last point in particular is pertinent. Our standards are not intended to be
read by any general audience -- although anyone is invited and encouraged to do
so! -- rather, they are primarily intended to guide processes of software
development in order to maximise compliance of software with our standards at
the time of initial submission. Most of the burden of aligning software with
our standards is thus expected to be borne by developers, who will be primarily
obliged to adhere to our standards. Such obligatory adherence is one of the
most effective ways to ensure that those most able to ensure software aligns
with our standards -- that is, the developers themselves -- both actually read
the standards, and ensure optimal alignment.

Aligning software with standards prior to submission has the additionally
important function of freeing reviewers from the otherwise potentially onerous
task of identifying and discussing generic or typical software-specific issues
or problems, enabling reviews to better focus on broader, more qualitative
aspects of software quality.

Finally, this project has already developed tools for the automated assessment
of software against a number of our standards, and we will strive for ongoing
expansion of automated assessment. Thus, even if our standards themselves
expand in time, hopefully the process of aligning software to meet those
standards will nevertheless become easier through continued development of our
tools for automated software assessment.


## Assessment and Peer-Review Processes

As described above, software will be expected to have been extensively assessed
by developers prior to submission, in particular to ensure optimal alignment of
submissions with both general and category-specific standards. Our process for
peer-review is described at length in [Chapter 6](#assessment). That process
begins by describing a number of steps expected to be completed by developers
prior to initial submission. The two primary stages of submission itself are
then described, followed by descriptions of the actual review process. While
all stages of this process are important for developers, reviewers need only
read and respond in accordance to Sections XX onwards.

In terms both of software itself, and associated communities of developers,
reviewers, and users, case the project will strive to cultivate diverse,
inclusive, and geographically expansive communities. Note that while these
aspects of community are not explicitly addressed throughout any of the
remainder of this document, it is important that future revisions return to
this point, and ensure that each of the following sections are appropriately
modified to ensure effective consideration and incorporation of the
representativeness and inclusiveness of communities surrounding our software.
