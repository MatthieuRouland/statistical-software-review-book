
# <span style="color:red;">Standards [SEEKING FEEDBACK]<span> {#standards}

This Chapter is divided between:

-   "*General Standards*" which may be applied to all software considered within
    this project, irrespective of how it may be categorized under the times of
    categories of statistical software listed above; and

-   "*Specific Standards*" which apply to different degrees to statistical
    software depending on the software category.

It is likely that standards developed under the first category may subsequently
be deemed to be genuinely *Statistical Standards* yet which are applicable
across all categories, and it may also be likely that the development of
category-specific standards reveals aspects which are common across all
categories, and which may subsequently be deemed general standards. We
accordingly anticipate a degree of fluidity between these two broad categories.

There is also a necessary relationship between the Standards described here,
and processes of Assessment described below in [Chapter 8](#assessment). We
consider the latter to describe concrete *and generally quantitative* aspects
of *post hoc* software assessment, while the present Standards provides guides
and benchmarks against which to *prospectively* compare software during
development. As this entire document is intended to serve as the defining
reference for our Standards, that term may in turn be interpreted to reflect
this entire document, with the current section explicitly describing aspects of
Standards not covered elsewhere.

As described above, we anticipate the ongoing development of this current
document to employ a versioning system, with software reviewed and hosted under
the system mandated to flag the latest version of these standards to which it
complies.

## Other Standards

Among the noteworthy instances of software standards which might be adapted for
our purposes, and in addition to entries in our [*Annotated
Bibliography*](#reading), the following are particularly relevant:

1. The [Core Infrastructure Initiative's Best Practices
   Badge](https://bestpractices.coreinfrastructure.org/en), which is granted to
   software meeting an extensive list of
   [criteria](https://github.com/coreinfrastructure/best-practices-badge/blob/master/doc/criteria.md).
   This list of criteria provides a singularly useful reference for software
   standards.
2. The [Software Sustainability Institute](https://www.software.ac.uk/)'s
   [*Software Evaulation
   Guide*](https://www.software.ac.uk/resources/guides-everything/software-evaluation-guide),
   in particular their guide to [*Criteria-based software
   evaluation*](http://software.ac.uk/sites/default/files/SSI-SoftwareEvaluationCriteria.pdf),
   which considers two primary categories of *Usability* and *Sustainability
   and Maintainability*, each of which is divided into numerous sub-categories.
   The guide identifies numerous concrete criteria for each sub-category,
   explicitly detailed below in order to provide an example of the kind of
   standards that might be adapted and developed for application to the present
   project.
3. The [*Transparent Statistics
   Guidelines*](https://transparentstats.github.io/guidelines/), by the "HCI
   (Human Computer Interaction) Working Group". While currently only in its
   beginning phases, that document aims to provide concrete guidance on
   "transparent statistical communication." If its development continues, it is
   likely to provide useful guidelines on best practices for how statistical
   software produces and reports results.
4. The more technical considerations of the [Object Management
   Group](https://www.omg.org/index.htm)'s [*Automated Source Code CISQ
   Maintainability Measure*](https://www.omg.org/spec/ASCMM/) (where CISQ
   refers to the [*Consortium for IT Software
   Quality*](https://www.it-cisq.org/)). This guide describes a number of
   measures which can be automatically extracted and used to quantify the
   maintainability of source code. None of these measures are not already
   considered in one or both of the preceding two documents, but the
   identification of measures particularly amenable to automated assessment
   provides a particularly useful reference.

There is also rOpenSci's guide on [package development, maintenance, and peer
review](https://devguide.ropensci.org/), which provides standards of this type
for R packages, primarily within its first chapter. Another notable example is
the [tidyverse design guide](https://principles.tidyverse.org/), and the
section on [Conventions for R Modeling
Pacakges](https://tidymodels.github.io/model-implementation-principles/) which
provides guidance for model-fitting APIs.


Specific standards for neural network algorithms have also been developed as
part of a [google 2019 Summer Of Code
project](http://www.inmodelia.com/gsoc2019.html), resulting in a dedicated
R package, [`NNbenchmark`](https://akshajverma.com/NNbenchmarkWeb/index.html),
and accompanying results---their so-called
["notebooks"](https://akshajverma.com/NNbenchmarkWeb/notebooks.html)---of
applying their benchmarks to a suite of neural network packages.

## Generally Applicable Standards 

The project aims to establish and maintain a set of standards governing general
aspects of software, such as software interfaces, documentation, and testing.

<!---
https://github.com/tdwg/vocab/blob/master/sds/documentation-specification.md
--->

<!---
Each debian release must include a space-separated list of bug report
   numbers closed by that release.
--->

### Documentation

Standards will include requirements for form and completeness of documentation.
As with interface, several sources already provide starting points for
reasonable documentation. Some documentation requirements will be specific to
the statistical context. For instance, it is likely we will have requirements
for referencing appropriate literature or references for theoretical support of
implementations. Another area of importance is correctness and clarity of
definitions of statistical quantities produced by the software, e.g., the
definition of null hypotheses or confidence intervals. Data included in
software -- that used in examples or tests -- will also have documentation
requirements. It is worth noting that the
[`roxygen`](https://roxygen2.r-lib.org/) system for documenting R packages is
readily extensible, as exemplified through the [`roxytest`
package](https://github.com/mikldk/roxytest) for specifying tests *in-line*.

The following standards describe several forms of what might be considered
"Supplementary Material". While there are many places within an R package where
such material may be included, common locations include vignettes, or in
additional directories (such as `data-raw`) listed in `.Rbuildignore` to
prevent inclusion within installed packages.

Where software supports a publication, all claims made in the publication with
regard to software performance (for example, claims of algorithmic scaling or
efficiency; or claims of accuracy), the following standard applies:

- **G1.0** Software should include all code necessary to reproduce results which
  form the basis of performance claims made in associated publications.

Where claims regarding aspects of software performance are made with respect to
other extant R packages, the following standard applies:

- **G1.1** Software should include code necessary to compare performance claims
  with alternative implementations in other R packages.


### Input Structures

This section considers general standards for *Input Structures*. These
standards may often effectively be addressed through implementing class
structures, although this is not a general requirement. Developers are
nevertheless encouraged to examine the guide to [S3
vectors](https://vctrs.r-lib.org/articles/s3-vector.html#casting-and-coercion)
in the [`vctrs` package](https://vctrs.r-lib.org) as an example of the kind of
assurances and validation checks that are possible with regard to input data.
Systems like those demonstrated in that vignette provide a very effective way
to ensure that software remains robust to diverse and unexpected classes and
types of input data.

#### Uni-variate (Vector) Input

It is important to note for univariate data that single values in R are vectors
with a length of one, and that `1` is of exactly the same *data type* as `1:n`.
Given this, inputs expected to be univariate should:

- **G2.0** Provide explicit secondary documentation of any expectations on lengths
  of inputs (generally implying identifying whether an input is expected to be
  single- or multi-valued)
- **G2.1** Provide explicit secondary documentation of expectations on *data types*
  of all vector inputs (see the above list).
- **G2.2** Appropriately prohibit or restrict submission of multivariate input to
  parameters expected to be univariate.
- **G2.3** For univariate character input:
    - **G2.3a** Use `match.arg()` or equivalent where applicable to only permit
      expected values.
    - **G2.3b** Either: use `tolower()` or equivalent to ensure input of
      character parameters is not case dependent; or explicitly document that
      parameters are strictly case-sensitive.
- **G2.4** Provide appropriate mechanisms to convert between different *data
  types*, potentially including:
    - **G2.4a** explicit conversion to `integer` via `as.integer()`
    - **G2.4b** explicit conversion to continuous via `as.numeric()`
    - **G2.4c** explicit conversion to character via `as.character()` (and not
      `paste` or `paste0`)
    - **G2.4d** explicit conversion to factor via `as.factor()`
    - **G2.4e** explicit conversion from factor via `as...()` functions
- **G2.5** Where inputs are expected to be of `factor` type, secondary
  documentation should explicitly state whether these should be `ordered` or
  not, and those inputs should provide appropriate error or other routines to
  ensure inputs follow these expectations.


### 2.2 Tabular Input

This sub-section concerns input in "tabular data" forms, implying the two
primary distinctions within R itself between `array` or `matrix`
representations, and `data.frame` and associated representations. Among
important differences between these two forms are that `array`/`matrix` classes
are restricted to storing data of a single uniform type (for example, all
`integer` or all `character` values), whereas `data.frame` as associated
representations store each column as a list item, allowing different columns to
hold values of different types. Further noting that
a `matrix` may, [as of R version
4.0](https://developer.r-project.org/Blog/public/2019/11/09/when-you-think-class.-think-again/index.html),
be considered as a strictly two-dimensional array, tabular inputs for the
purposes of these standards are considered to imply data represented in one or
more of the following forms:

Given this, tabular inputs may be in one or or more of the following forms:

- `matrix` form when referring to specifically two-dimensional data of one
  uniform type
- `array` form as a more general expression, or when referring to data that are
  not necessarily or strictly two-dimensional
- `data.frame`
- Extensions such as
    - [`tibble`](https://tibble.tidyverse.org)
    - [`data.table`](https://rdatatable.gitlab.io/data.table)
    - domain-specific classes such as
      [`tsibble`](https://tsibble.tidyverts.org) for time series, or
      [`sf`](https://r-spatial.github.io/sf/) for spatial data.

The term "`data.frame` and associated forms" is assumed to refer to data
represented in either the `base::data.frame` format, and/or any of the classes
listed in the final of the above points.

General Standards applicable to software which is intended to accept any one or
more of these tabular inputs are then that:

- **G2.5** Software should accept as input as many of the above standard tabular
  forms as possible, including extension to domain-specific forms
- **G2.6** Software should provide appropriate conversion routines as part of initial
  pre-processing to ensure that all other sub-functions of a package receive
  inputs of a single defined class or type.
- **G2.7** Software should issue diagnostic messages for type conversion in which
  information is lost (such as conversion of variables from factor to
  character; standardisation of variable names; or removal of meta-data such as
  those associated with [`sf`-format](https://r-spatial.github.io/sf/) data) or
  added (such as insertion of variable or column names where none were
  provided).

The next standard concerns the following inconsistencies between three common
tabular classes in regard the column extraction operator, `[`.

``` r
class (x) # x is any kind of `data.frame` object
#> [1] "data.frame"
class (x [, 1])
#> [1] "integer"
class (x [, 1, drop = TRUE]) # default
#> [1] "integer"
class (x [, 1, drop = FALSE])
#> [1] "data.frame"

x <- tibble::tibble (x)
class (x [, 1])
#> [1] "tbl_df"     "tbl"        "data.frame"
class (x [, 1, drop = TRUE])
#> [1] "integer"
class (x [, 1, drop = FALSE]) # default
#> [1] "tbl_df"     "tbl"        "data.frame"

x <- data.table::data.table (x)
class (x [, 1])
#> [1] "data.table" "data.frame"
class (x [, 1, drop = TRUE]) # no effect
#> [1] "data.table" "data.frame"
class (x [, 1, drop = FALSE]) # default
#> [1] "data.table" "data.frame"
```

- Extracting a single column from a `data.frame` returns a `vector` by default,
  and a `data.frame` if `drop = FALSE`.
- Extracting a single column from a `tibble` returns a single-column `tibble`
  by default, and a `vector` is `drop = TRUE`. 
- Extracting a single column from a `data.table` always returns a `data.table`,
  and the `drop` argument has no effect.

Given such inconsistencies, 

- **G2.8** Software should ensure that extraction or filtering of single columns
  from tabular inputs should not presume any particular default behaviour, and
  should ensure all column-extraction operations behave consistently regardless
  of the class of tabular data used as input.

Adherence to the above standard G2.6 will ensure that any implicitly or
explicitly assumed default behaviour will yield consistent results regardless
of input classes.

#### Missing or Undefined Values

- **G2.9** Statistical Software should implement appropriate checks for missing
  data as part of initial pre-processing prior to passing data to analytic
  algorithms.
- **G2.10** Where possible, all functions should provide options for users to
  specify how to handle missing (`NA`) data, with options minimally including:
  - **G2.10a** error on missing data
  - **G2.10b** ignore missing data with default warnings or messages issued
  - **G2.10c** replace missing data with appropriately imputed values
- **G2.11** Functions should never assume non-missingness, and should never pass
  data with potential missing values to any base routines with default `na.rm =
  FALSE`-type parameters (such as
  [`mean()`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/mean.html),
  [`sd()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/sd.html) or
  [`cor()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cor.html)).
- **G2.12** All functions should also appropriately handle undefined values 
  (e.g., `NaN`, `Inf` and `-Inf`), including potentially providing options for
  ignoring or removing such values.

### Output Structures

- **G3.0** Statistical Software which enables outputs to be written to local files
  should parse parameters specifying file names to ensure appropriate file
  suffices are automatically generated where not provided.

### Testing {#standards-testing}

All packages should follow rOpenSci standards on
[testing](https://devguide.ropensci.org/building.html#testing) and [continuous
integration](https://devguide.ropensci.org/ci.html), including aiming for high
test coverage. Extant R packages which may be useful for testing include
[`testthat`](https://testthat.r-lib.org),
[`tinytest`](https://github.com/markvanderloo/tinytest),
[`roxytest`](https://github.com/mikldk/roxytest), and
[`xpectr`](https://github.com/LudvigOlsen/xpectr).

- **G4.0** Where applicable or practicable, tests should use standard data sets
  with known properties (for example, the [NIST Standard Reference
  Datasets](https://www.itl.nist.gov/div898/strd/), or data sets provided by
  other widely-used R packages).
- **G4.1** Data sets created within, and used to test, a package should be
  exported (or otherwise made generally available) so that users can confirm
  tests and run examples.

For testing _statistical algorithms_, tests should include tests of the
following types:

- **G4.2** **Correctness tests** to test that statistical algorithms produce
   expected results to some fixed test data sets (potentially through
   comparisons using binding frameworks such as
   [RStata](https://github.com/lbraglia/RStata)).
    - **G4.2a** For new methods, it can be difficult to separate out
       correctness of the method from the correctness of the
       implementation, as there may not be reference for comparison.  In this
       case, testing may be implemented against simple, trivial cases or
       against multiple implementations such as an initial R implementation
       compared with results from a C/C++ implementation.
    - **G4.2b** For new implementations of existing methods, correctness tests
      should include tests against previous implementations.  Such testing may
      explicitly call those implementations in testing, preferably from
      fixed-versions of other software, or use stored outputs from those where
      that is not possible.
    - **G4.2c** Where applicable, stored values may be drawn from published
      paper outputs when applicable and where code from original
      implementations is not available
- **G4.3** Correctness tests should be run with a fixed random seed
- **G4.4** **Parameter recovery tests** to test that the implementation produce
  expected results given data with known properties.  For instance, a linear
  regression algorithm should return expected coefficient values for a
  simulated data set generated from a linear model.
    - **G4.4a** Parameter recovery tests should generally be expected to
      succeed within a defined tolerance rather than recovering exact values.
    - **G4.4b** Parameter recovery tests should be run with multiple random
      seeds when either data simulation or the algorithm contains a random
      component
- **G4.5** **Algorithm performance tests** to test that implementation performs
  as expected as properties of data change.  For instance, a test may show that
  parameters approach correct estimates within tolerance as data size
  increases, or that convergence times decrease for higher convergence
  thresholds.
- **G4.6** **Edge condition tests** to test that these conditions produce
  expected behaviour such as clear warnings or errors when confronted with data
  with extreme properties including but not limited to:
    - **G4.6a** Zero-length data, 
    - **G4.6b** Data of unsupported types (e.g., character or complex numbers
      in for functions designed only for numeric data)
    - **G4.6c** Data with all-`NA` fields or columns or all identical fields or columns
    - **G4.6d** Data outside the scope of the algorithm (for example, data with
      more fields (columns) than observations (rows) for some regression
      algorithms)
- **G4.7** **Noise susceptibility tests** Packages should test for expected
  stochastic behaviour, such as through the following conditions:
    - **G4.7a** Adding trivial noise (for example, at the scale of
      `.Machine$double.eps`) to data does not meaningfully change results
    - **G4.7b** Running under different random seeds or initial conditions does
      not meaningfully change results

### 4.1 Extended tests

Thorough testing of statistical software may require tests on large data sets, 
tests with many permutations, or other conditions leading to long-running
tests. In such cases it may be neither possible nor advisable to execute tests
continuously, or with every code change. Software should nevertheless test any
and all conditions regardless of how long tests may take, and in doing so
should adhere to the following standards:

- **G4.8** Extended tests should included and run under a common framework with
  other tests but be switched on by flags such as as a
  `<MYPKG>_EXTENDED_TESTS=1` environment variable.
- **G4.9** Where extended tests require large data sets or other assets, these
  should be provided for downloading and fetched as part of the testing
  workflow.
    - **G4.9a** When any downloads of additional data necessary for extended
      tests fail, the tests themselves should not fail, rather be skipped and
      implicitly succeed with an appropriate diagnostic message.
- **G4.10** Any conditions necessary to run extended tests such as platform
  requirements, memory, expected runtime, and artefacts produced that may need
  manual inspection, should be described in developer documentation such as a
  `CONTRIBUTING.md` or `tests/README.md` file. 


## Standards Specific to Statistical Software

We now consider standards specific to the categories described in the [previous
chapter](#scope). We have to date developed initial standards for four of these
categories.

### Bayesian and Monte Carlo Routines {#standards-category-bayesian}

Bayesian and Monte Carlo Software (hereafter referred to for simplicity as
Bayesian and Monte Carlo Software (hereafter referred to for simplicity as
"Bayesian Software") is presumed to perform one or more of the following steps:

- 1. Document how to specify inputs including:
    - 1.1 Data
    - 1.2 Hyperparameters determining prior distributions
    - 1.3 Parameters determining the computational processes
- 2. Accept and validate all of forms of input
- 3. Apply data transformation and pre-processing steps
- 4. Apply one or more analytic algorithms, generally sampling algorithms used to
   generate estimates of posterior distributions
- 5. Return the result of that algorithmic application
- 6. Offer additional functionality such as printing or summarising return results

This document details standards for each of these steps, each prefixed with "BM".

#### Documentation of Inputs

Prior to actual standards for documentation of inputs, we note one
terminological standard for Bayesian software:

- **BS1.0** Bayesian software should use the term "hyperparameter" exclusively to
  refer to parameters determining the form of prior distributions, and should
  use either the generic term "parameter" or some conditional variant(s) such
  as "computation parameters" to refer to all other parameters.

Bayesian Software should provide the following documentation of how to specify
inputs:

- **BS1.1** Description of how to enter data, both in textual form and via code
  examples. Both of these should consider the simplest cases of single objects
  representing independent and dependent data, and potentially more complicated
  cases of multiple independent data inputs.
- **BS1.2** Description of how to specify prior distributions, both in textual form
  describing the *general principles* of specifying prior distributions, along
  with more applied descriptions and examples, within:
    - **B31.2a** The main package `README`, either as textual description or example code
    - **B31.2b** At least one package vignette, both as general and applied textual
      descriptions, and example code
    - **B31.2c** Function-level documentation, preferably with code included in examples
- **BS1.3** Description of all parameters which control the computational process
  (typically those determining aspects such as numbers and lengths of sampling
  processes, seeds used to start them, thinning parameters determining post-hoc
  sampling from simulated values, and convergence criteria). In particular:
    - **BS1.3a** Bayesian Software should document, both in text and examples, how
      to use the output of previous simulations as starting points of
      subsequent simulations.
    - **BS1.3b** Where applicable, Bayesian software should document, both in text
      and examples, how to use different sampling algorithms for a given model.
- **BS1.4** For Bayesian Software which implements or otherwise enables convergence
  checkers, documentation should explicitly describe and provide examples of
  use with and without convergence checkers.
- **BS1.5** For Bayesian Software which implements or otherwise enables *multiple*
  convergence checkers, differences between these should be explicitly tested.

#### Input Data Structures and Validation

This section contains standards primarily intended to ensure that input data,
including model specifications, are validated prior to passing through to the
main computational algorithms.

**Input Data**

Bayesian Software is commonly designed to accept generic one- or
two-dimensional forms such as vector, matrix, or `data.frame` objects. The
first standards concerns the range of possible generic forms for input *data*:

- **BS2.0** Bayesian Software which accepts one-dimensional input should ensure
  values are appropriately pre-processed regardless of class structures. The
  [`units` package](https://github.com/r-quantities/units/) provides a good
  example, in creating objects that may be treated as vectors, yet which have a
  class structure that does not inherit from the `vector` class. Using these
  objects as input often causes software to fail. The `storage.mode` of the
  underlying objects may nevertheless be examined, and the objects transformed
  or processed accordingly to ensure such inputs do not lead to errors.
- **BS2.1** Bayesian Software which accepts two-dimension input should implement
  pre-processing routines to ensure conversion of as many possible forms as
  possible to some standard format which is then passed to all analytic
  functions. In particular, tests should demonstrate that:
    - **BS2.1a** `data.frame` or equivalent objects which have columns which do not
      themselves have standard class attributes (typically, `vector`) are
      appropriately processed, and do not error without reason. This behaviour
      should be tested. Again, columns created by the [`units`
      package](https://github.com/r-quantities/units/) provide a good test
      case.
    - **BS2.1b** `data.frame` or equivalent objects which have list columns should
      ensure that those columns are appropriately pre-processed either through
      being removed, converted to equivalent vector columns where appropriate,
      or some other appropriate treatment. This behaviour should be tested.
- **BS2.2** Bayesian Software should implement pre-processing routines to ensure
  all input data is dimensionally commensurate, for example by ensuring
  commensurate lengths of vectors or numbers of rows of rectangular inputs.


**Prior Distributions, Model Specifications, and Hyperparameters**

The second set of standards in this section concern specification of prior
distributions, model structures, or other equivalent ways of specifying
hypothesised relationships among input data structures. R already has a diverse
range of Bayesian Software with distinct approaches to this task, commonly
either through specifying a model as a character vector representing an R
function, or an external file either as R code, or encoded according to some
alternative system (such as for [`rstan`](https://mc-stan.org/rstan/)).

As explicated above, the term "hyperparameters" is interpreted here to refer to
parameters which define prior distributions, while a "model specification", or
simply "model", is an encoded description of how those hyperparameters are
hypothesised to transform to a posterior distribution.

Bayesian Software should:

- **BS2.3** Ensure that all appropriate validation and pre-processing of
  hyperparameters are implemented as distinct *pre-processing* steps prior to
  submitting to analytic routines, and especially prior to submitting to
  multiple parallel computational chains.
- **BS2.4** Ensure that lengths of hyperparameter vectors are checked, with no
  excess values silently discarded (unless such output is explicitly
  suppressed, as detailed below).
- **BS2.5** Ensure that lengths of hyperparameter vectors are commensurate with
  expected model input (see example immediately below)
- **BS2.6** Where possible, implement pre-processing checks to validate
  appropriateness of numeric values submitted for hyperparameters; for example,
  by ensuring that hyperparameters defining second-order moments such as
  distributional variance or shape parameters, or any parameters which are
  logarithmically transformed, are non-negative. 

The following example demonstrates how standards like the above (BS2.5-2.6)
might be addressed. Consider the following function which defines a
log-likelihood estimator for a linear regression, controlled via a vector of
three hyperparameters, `p`:

``` r
ll <- function (x, y, p) dnorm (y - (p[1] + x * p[2]), sd = p[3], log = TRUE)
```

Pre-processing stages should be used to determine:

1. That the dimensions of the input data, `x` and `y`, are commensurate (BS2.2);
   non-commensurate inputs should error by default.
2. The length of the vector `p` (BS2.4)

The latter task is not necessarily straightforward, because the definition of
the function, `ll()`, will itself generally be part of the input to an actual
Bayesian Software function. This functional input thus needs to be examined to
determine expected lengths of hyperparameter vectors. The following code
illustrates one way to achieve this, relying on utilities for parsing function
calls in R, primarily through the
[`getParseData`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/getParseData.html)
function from the `utils` package. The parse data for a function can be
extracted with the following line:
``` r
x <- getParseData (parse (text = deparse (ll)))
```
The object `x` is a `data.frame` of every R token (such as an expression,
symbol, or operator) parsed from the function `ll`. The following section
illustrates how this data can be used to determine the expected lengths of
vector inputs to the function, `ll()`.

<details>
<summary>
click to see details
</summary>
<p>

Input arguments used to define parameter vectors in any R software are accessed
through R's standard vector access syntax of `vec[i]`, for some element `i` of
a vector `vec`. The parse data for such begins with the `SYMBOL` of `vec`, the
`[`, a `NUM_CONST` for the value of `i`, and a closing `]`. The following code
can be used to extract elements of the parse data which match this pattern, and
ultimately to extract the various values of `i` used to access members of
`vec`.

``` r
vector_length <- function (x, i) {
    xn <- x [which (x$token %in% c ("SYMBOL", "NUM_CONST", "'['", "']'")), ]
    # split resultant data.frame at first "SYMBOL" entry
    xn <- split (xn, cumsum (xn$token == "SYMBOL"))
    # reduce to only those matching the above pattern
    xn <- xn [which (vapply (xn, function (j)
                             j$text [1] == i & nrow (j) > 3,
                             logical (1)))]
    ret <- NA_integer_ # default return value
    if (length (xn) > 0) {
        # get all values of NUM_CONST as integers
        n <- vapply (xn, function (j)
                         as.integer (j$text [j$token == "NUM_CONST"] [1]),
                         integer (1), USE.NAMES = FALSE)
        # and return max of these
        ret <- max (n)
    }
    return (ret)
}
```

That function can then be used to determine the length of any inputs which are
used as hyperparameter vectors:

``` r
ll <- function (p, x, y) dnorm (y - (p[1] + x * p[2]), sd = p[3], log = TRUE)
p <- parse (text = deparse (ll))
x <- utils::getParseData (p)

# extract the names of the parameters:
params <- unique (x$text [x$token == "SYMBOL"])
lens <- vapply (params, function (i) vector_length (x, i), integer (1))
lens
#>  y  p  x 
#> NA  3 NA
```

And the vector `p` is used as a hyperparameter vector containing three
parameters. Any initial value vectors can then be examined to ensure that they
have this same length.

----

</p>
</details><br>

Not all Bayesian Software is designed to accept model inputs expressed as R
code. The [`rstan` package](https://github.com/stan-dev/rstan), for example,
implements its own model specification language, and only allows
hyperparameters to be named, and not addressed by index. While this largely
avoids problems of mismatched lengths of parameter vectors, the software (at
v2.21.1) does not ensure the existence of named parameters prior to starting
the computational chains. This ultimately results in each chain generating an
error when a model specification refers to a non-existent or undefined
hyperparameter. Such controls should be part of a single pre-processing stage,
and so should only generate a single error.

**Computational Parameters**

Computational parameters are considered here as those passed to Bayesian
functions other than hyperparameters determining the forms of prior
distributions. They typically include parameters controlling lengths of runs,
lengths of burn-in periods, numbers of parallel computations, other parameters
controlling how samples are to be generated, or convergence criteria. All
Computational Parameters should be checked for general "sanity" prior to
calling primary computational algorithms. The standards for such sanity checks
include that Bayesian Software should:

- **BS2.7** Check that values for parameters are positive (except where negative
  values may be accepted)
- **BS2.8** Check lengths and/or dimensions of inputs, and either automatically
  reject or provide appropriate diagnostic messaging for parameters of
  inappropriate length or dimension; for example passing a vector of length > 1
  to a parameter presumed to define a single value (unless such output is
  explicitly suppressed, as detailed below)
- **BS2.9** Check that arguments are of expected classes or types (for example,
  check that `integer`-type arguments are indeed `integer`, with explicit
  conversion via `as.integer` where not)
- **BS2.10** Automatically reject parameters of inappropriate type (for example
  `character` values passed for `integer`-type parameters that are unable to be
  appropriately converted).

The following two sub-sections consider particular cases of computational
parameters.

**Seed Parameters**

Bayesian software should:

- **BS2.11** Enable seeds to be passed as a parameter (through a direct `seed`
  argument or similar), or as a vector of parameters, one for each chain.
- **BS2.12** Enable results of previous runs to be used as starting points for
  subsequent runs

Bayesian Software which implements parallel processing should:

- **BS2.13** Ensure each chain is started with a different seed by default
- **BS2.14** Issue diagnostic messages when identical seeds are passed to distinct
  computational chains
- **BS2.15** Explicitly document advice *not* to use `set.seed()`
- **BS2.16** Provide the parameter with a *plural* name: for example,
  "starting_values" and not "starting_value"

To avoid potential confusion between separate parameters to control random
seeds and starting values, we recommended a single "starting values" rather
than "seeds" argument, with appropriate translation of these parameters into
seeds where necessary.

**Output Verbosity**

All Bayesian Software should implement computational parameters to control
output verbosity. Bayesian computations are often time-consuming, and often
performed as batch computations. The following standards should be adhered to
in regard to output verbosity:

- **BS2.17** Bayesian Software should implement at least one parameter controlling
  the verbosity of output, defaulting to verbose output of all appropriate
  messages, warnings, errors, and progress indicators.
- **BS2.18** Bayesian Software should enable suppression of messages and progress
  indicators, while retaining verbosity of warnings and errors. This should be
  tested.
- **BS2.19** Bayesian Software should enable suppression of warnings where
  appropriate. This should be tested.
- **BS2.20** Bayesian Software should explicitly enable errors to be caught, and
  appropriately processed either through conversion to warnings, or otherwise
  captured in return values. This should be tested.


#### Pre-processing and Data Transformation

**Missing Values**

Bayesian Software should:

- **BS3.0** Explicitly document assumptions made in regard to missing values; for
  example that data is assumed to contain no missing (`NA`, `Inf`) values, and
  that such values, or entire rows including any such values, will be
  automatically removed from input data.
- **BS3.1** Implement appropriate routines to pre-process missing values prior to
  passing data through to main computational algorithms.


**Perfect Collinearity**

Where appropriate, Bayesian Software should:

- **BS3.2** Implement pre-processing routines to diagnose perfect collinearity, and
  provide appropriate diagnostic messages or warnings
- **BS3.3** Provide distinct routines for processing perfectly collinear data,
  potentially bypassing sampling algorithms

An appropriate test for BS3.3 would confirm that `system.time()` or equivalent
timing expressions for perfectly collinear data should be *less* than
equivalent routines called with non-collinear data. Alternatively, a test could
ensure that perfectly collinear data passed to a function with a stopping
criteria generated no results, while specifying a fixed number of iterations
may generate results.

#### Analytic Algorithms

As mentioned, analytic algorithms for Bayesian Software are commonly algorithms
to simulate posterior distributions, and to draw samples from those
simulations. Numerous extent R packages implement and offer sampling
algorithms, and not all Bayesian Software will internally implement sampling
algorithms. The following standards apply to packages which do implement
internal sampling algorithms:


- **BS4.0** Packages should document sampling algorithms (generally via
  literary citation, or reference to other software)
- **BS4.1** Packages should provide explicit comparisons with external samplers
  which demonstrate intended advantage of implementation (generally via tests,
  vignettes, or both).

Regardless of whether or not Bayesian Software implements internal sampling
algorithms, it should:

- **BS4.2** Implement at least one means to validate posterior estimates (for
  example through the functionality of the [`BayesValidate`
  package](https://cran.r-project.org/package=BayesValidate), noting that that
  package has not been updated for almost 15 years, and such approaches may
  need adapting; or the [Simulation Based
  Calibration](https://arxiv.org/abs/1804.06788) approach implemented in the
  [`rstan`](https://mc-stan.org/rstan) function
  [`sbc`](https://mc-stan.org/rstan/reference/sbc.html)).

Where possible or applicable, Bayesian Software should:

- **BS4.3** Implement at least one type of convergence checker, and provide a
  documented reference for that implementation.
- **BS4.3** Enable computations to be stopped on convergence (although not
  necessarily by default).
- **BS4.5** Ensure that appropriate mechanisms are provided for models which do not
  converge. This is often achieved by having default behaviour to stop after
  specified numbers of iterations regardless of convergence.
- **BS4.6** Implement tests to confirm that results with convergence checker are
  statistically equivalent to results from equivalent fixed number of samples
  without convergence checking.
- **BS4.7** Where convergence checkers are themselves parametrised, the effects of
  such parameters should also be tested. For threshold parameters, for example,
  lower values should result in longer sequence lengths.


#### Return Values

Unlike software in many other categories, Bayesian Software should generally
return several kinds of distinct data, both the raw data derived from
statistical algorithms, and associated metadata. Such distinct and generally
disparate forms of data will be generally best combined into a single object
through implementing a defined class structure, although other options are
possible, including (re-)using extant class structures (see the CRAN Task view
on [Bayesian Inference](https://cran.r-project.org/web/views/TimeSeries.html).
https://cran.r-project.org/web/views/Bayesian.html) for reference to other
packages and class systems). Regardless of the precise form of return object,
and whether or not defined class structures are used or implemented, the
objects returned from Bayesian Software should include:

- **BS5.0** Seed(s) or starting value(s), including values for each sequences where
  multiple sequences are included
- **BS5.1** Appropriate metadata on types (or classes) and dimensions of input data


With regard to the input function, or alternative means of specifying prior
distributions:

- **BS5.2** Bayesian Software should either:
    - **BS5.2a** Return the input function or prior distributional specification in the return object; or
    - **BS5.2b** Enable direct access to such via additional functions which accept
      the return object as single argument.

Where convergence checkers are implemented or provided, Bayesian Software should:

- **BS5.3** Return convergence statistics or equivalent
- **BS5.4** Where multiple checkers are enabled, return details of convergence
  checker used 
- **BS5.5** Appropriate diagnostic statistics to indicate absence of convergence
  are either returned or immediately able to be accessed.

#### Additional Functionality

Bayesian Software should:

- **BS6.0** Implement a default `print` method for return objects
- **BS6.1** Implement a default `plot` method for return objects
- **BS6.2** Provide and document straightforward abilities to plot sequences of
  posterior samples, with burn-in periods clearly distinguished
- **BS6.3** Provide and document straightforward abilities to plot posterior
  distributional estimates

Bayesian Software may:

- **BS6.4** Provide `summary` methods for return objects
- **BS6.5** Provide abilities to plot both sequences of posterior samples and
  distributional estimates together in single graphic



#### Testing

- Parameter recoveery tests:
   -   Recover the prior woth no data or data with no information, especially where priors are implicit.  
   -   Even in empirical bayes, recover the estimated prior
   -   Recover posterior given expected data *and* prior

-  Algorithmic scaling tests with data - is it linear, log, etc
-  Test for prediction/fitted values on same scale as input values


### Regression and Supervised Learning {#standards-category-supervised}

This document details standards for Regression and Supervised Learning
Software -- referred to from here on for simplicity as "Regression Software".
Regression Software implements algorithms which aim to construct or analyse one
or more mappings between two defined data sets (for example, a set of
"independent" data, $X$, and a set of "dependent" data, $Y$). In contrast, the
analogous category of Unsupervised Learning Software aims to construct or
analyse one or more mappings between a defined set of input or independent
data, and a second set of "output" data which are not necessarily known or
given prior to the analysis.

Common purposes of Regression Software are to fit models to estimate
relationships or to make predictions between specified inputs and outputs.
Regression Software includes tools with inferential or predictive foci,
Bayesian, frequentist, or probability-free Machine Learning (ML) approaches,
parametric or or non-parametric approaches, discrete outputs (such as in
classification tasks) or continuous outputs, and models and algorithms specific
to applications or data such as time series or spatial data.  In many cases
other standards specific to these subcategories may apply.

The following standards are divided among several sub-categories, with each
standard prefixed with "RE".



#### Input data structures and validation

- **RE1.0** Regression Software should enable models to be specified via a formula
  interface, unless reasons for *not* doing so are explicitly documented.
- **RE1.1** Regression Software should document how formula interfaces are
  converted to matrix representations of input data. See Max Kuhn's [RStudio
  blog
  post](https://rviews.rstudio.com/2017/02/01/the-r-formula-method-the-good-parts/)
  for examples.
- **RE1.2** Regression Software should document expected format (types or classes)
  for inputting predictor variables, including descriptions of types or classes
  which are not accepted; for example, specification that software accepts only
  numeric inputs in `vector` or `matrix` form, or that all inputs must be in
  `data.frame` form with both column and row names.
- **RE1.3** Regression Software should explicitly document any aspects of input
  data (such as row names) which are not used in model construction.
- **RE1.4** Regression Software should document any assumptions made with regard to
  input data; for example distributional assumptions, or assumptions that
  predictor data have mean values of zero. Implications of violations of these
  assumptions should be both documented and tested.

#### Pre-processing and Variable Transformation

- **RE2.0** Regression Software should document any transformations applied to
  input data, for example conversion of label-values to `factor`, and should
  provide ways to explicitly avoid any default transformations (with error or
  warning conditions where appropriate).
- **RE2.1** Regression Software should implement explicit parameters controlling
  the processing of missing values, ideally distinguishing `NA` or `NaN` values
  from `Inf` values (for example, through use of `na.omit()` and related
  functions from the `stats` package).
- **RE2.2** Regression Software should provide different options for processing
  missing values in *predictor* and *response* data. For example, it should be
  possible to fit a model with no missing predictor data in order to generate
  values for all associated response points, even where submitted response
  values may be missing.
- **RE2.3** Where applicable, Regression Software should enable data to be centred
  (for example, through converting to zero-mean equivalent values; or to
  z-scores) or offset (for example, to zero-intercept equivalent values) via
  additional parameters, with the effects of any such parameters clearly
  documented and tested.
- **RE2.4** Regression Software should implement pre-processing routines to
  identify whether aspects of input data are perfectly collinear, notably
  including:
    - **RE2.4a** Perfect collinearity among predictor variables
    - **RE2.4b** Perfect collinearity between independent and dependent variables

These pre-processing routines should also be tested as described below.

#### Algorithms

The following standards apply to the model fitting algorithms of Regression
Software which implements or relies on iterative algorithms which are expected
to converge to generate model statistics. Regression Software which implements
or relies on iterative convergence algorithms should:

- **RE3.0** Issue appropriate warnings or other diagnostic messages for models
  which fail to converge.
- **RE3.1** Enable such messages to be optionally suppressed, yet should ensure
  that the resultant model object nevertheless includes sufficient data to
  identify lack of convergence.
- **RE3.2** Ensure that convergence thresholds have sensible default values,
  demonstrated through explicit documentation.
- **RE3.3** Allow explicit setting of convergence thresholds, unless reasons
  against doing so are explicitly documented.


#### Return Results

- **RE4.0** Regression Software should return some form of "model" object,
  generally through using or modifying existing class structures for model
  objects (such as `lm`, `glm`, or model objects from other packages), or
  creating a new class of model objects.
- **RE4.1** Regression Software may enable an ability to generate a model object
  without actually fitting values. This may be useful for controlling batch
  processing of computationally intensive fitting algorithms.

**Accessor Methods**

Regression Software should provide functions to access or extract as much of
the following kinds of model data as possible or practicable. Access should
ideally rely on class-specific methods which extend, or implement otherwise
equivalent versions of, the methods from the `stats` package which are named in
parentheses in each of the following standards.

The model objects should include, or otherwise enable effectively immediate
access to, 

- **RE4.2** Model coefficients (via `coeff()` / `coefficients()`)
- **RE4.3** Confidence intervals on those coefficients (via `confint()`)
- **RE4.4** The specification of the model, generally as a formula (via
  `formula()`)
- **RE4.5** Numbers of observations submitted to model (via `nobs()`)
- **RE4.6** The variance-covariance matrix of the model parameters (via `vcov()`)
- **RE4.7** Where appropriate, convergence statistics


Regression Software *should* provide simple and direct methods to return or
otherwise access the following form of data and metadata, where the latter
includes information on any transformations which may have been applied to the
data prior to submission to modelling routines.

- **RE4.8** Response variables, and associated "metadata" where applicable.
- **RE4.9** Modelled values of response variables.
- **RE4.10** Model Residuals, including sufficient documentation to enable
  interpretation of residuals, and to enable users to submit residuals to their
  own tests.
- **RE4.11** Goodness-of-fit and other statistics associated such as effect sizes
  with model coefficients.
- **RE4.12** Where appropriate, functions used to transform input data, and
  associated inverse transform functions.

Regression software *may* provide simple and direct methods to return or
otherwise access the following:

- **RE4.13** Predictor variables, and associated "metadata" where applicable.

**Extrapolation and Forecasting**

- **RE4.14** Where Regression Software is intended to, or can, be used to
  extrapolate or forecast values, values should also be provided for
  extrapolation or forecast *errors*.
- **RE4.15** Sufficient documentation and/or testing should be provided to
  demonstrate that forecast errors, confidence intervals, or equivalent values
  increase with forecast horizons.

**Reporting Return Results**

- **RE4.16** Model objects returned by Regression Software should implement or
  appropriately extend a default `print` method which provides an on-screen
  summary of model (input) parameters and (output) coefficients.
- **RE4.17** Regression Software may also implement `summary` methods for model
  objects, and in particular *should* implement distinct `summary` methods for
  any cases in which calculation of summary statistics is computationally
  non-trivial (for example, for bootstrapped estimates of confidence
  intervals).

#### Documentation

Beyond the general standards for documentation, Regression Software should
explicitly describe the following aspects, and ideally provide extended
documentation including graphical output: 

- **RE5.0** Scaling relationships between sizes of input data (numbers of
  observations, with potential extension to numbers of variables/columns) and
  speed of algorithm.

#### Visualization

- **RE6.0** Model objects returned by Regression Software (see RE3.0) should have
  default `plot` methods, either through explicit implementation, extension of
  methods for existing model objects, or through ensuring default methods work
  appropriately.
- **RE6.1** Where the default `plot` method is **NOT** a generic `plot` method
  dispatched on the class of return objects (that is, through
  a `plot.<myclass>` function), that method dispatch should nevertheless exist
  in order to explicitly direct users to the appropriate function.
- **RE6.2** The default `plot` method should produce a plot of the `fitted` values
  of the model, with optional visualisation of confidence intervals or
  equivalent.
- **RE6.3** Where a model object is used to generate a forecast (for example,
  through a `predict()` method), the default `plot` method should provide clear
  visual distinction between modelled (interpolated) and forecast
  (extrapolated) values.

#### Testing

Tests for Regression Software should include the following conditions and cases:

- **RE7.0** Tests with noiseless, exact relationships between predictor
  (independent) data.
    - **RE7.0a** In particular, these tests should confirm that model fitting is at
      least as fast or (preferably) faster than testing with equivalent noisy
      data (see RE2.4a).
- **RE7.1** Tests with noiseless, exact relationships between predictor
  (independent) and response (dependent) data.
    - **RE7.1a** In particular, these tests should confirm that model fitting is at
      least as fast or (preferably) faster than testing with equivalent noisy
      data (see RE2.4b).


### Exploratory Data Analysis (EDA) and Summary Statistics {#standards-category-EDA}

Exploration is a part of all data analyses, and Exploratory Data Analysis (EDA)
is not something that is entered into and exited from at some point prior to
"real" analysis. Exploratory Analyses are also not strictly limited to *Data*,
but may extend to exploration of *Models* of those data. The category could
thus equally be termed, "*Exploratory Data and Model Analysis*", yet we opt to
utilise the standard acronym of EDA in this document.

EDA is nevertheless somewhat different to many other categories included within
rOpenSci's program for peer-reviewing statistical software. Primary differences include:

- EDA software often has a strong focus upon visualization, which is a category
  which we have otherwise explicitly excluded from the scope of the project at
  the present stage.
- The assessment of EDA software requires addressing more general questions
  than software in most other categories, notably including the important
  question of intended audience(s).

The following standards are accordingly somewhat differently structured than
equivalent standards developed to date for other categories, particularly
through being more qualitative and abstract. In particular, while documentation
is an important component of standards for all categories, clear and
instructive documentation is of paramount importance for EDA Software, and so
warrants its own sub-section within this document.

#### Documentation Standards

The following refer to *Primary Documentation*, implying in main package
`README` or vignette(s), and *Secondary Documentation*, implying function-level
documentation.

The *Primary Documentation* (`README` and/or vignette(s)) of EDA software
should:

- **EA1.0** Identify one or more target audiences for whom the software is intended
- **EA1.1** Identify the kinds of data the software is capable of analysing (see
  *Kinds of Data* below).
- **EA1.2** Identify the kinds of questions the software is intended to help
  explore; for example, are these questions:
    - inferential?
    - predictive?
    - associative?
    - causal?
    - (or other modes of statistical enquiry?)

The *Secondary Documentation* (within individual functions) of EDA software
should:

- **EA1.3** Identify the kinds of data each function is intended to accept as input

#### Input Data

A further primary difference of EDA software from that of our other categories
is that input data for statistical software may be generally presumed of one or
more specific types, whereas EDA software often accepts data of more general
and varied types. EDA software should aim to accept and appropriately transform
as many diverse kinds of input data as possible, through addressing the
following standards, considered in terms of the two cases of input data in uni-
and multi-variate form. All of the general standards for kinds of input (G2.0 -
G2.7) apply to input data for EDA Software.

**Index Columns**

The following standards refer to an *index column*, which is understood to
imply an explicitly named or identified column which can be used to provide a
unique index index into any and all rows of that table. Index columns ensure
the universal applicability of standard table join operations, such as those
implemented via the [`dplyr` package](https://dplyr.tidyverse.org).

- **EA2.0** EDA Software which accepts standard rectangular data and implements or
  relies upon extensive table filter and join operations should utilise an
  *index column* system
- **EA2.1** All values in an index column must be unique, and this uniqueness
  should be affirmed as a pre-processing step for all input data.
- **EA2.2** Index columns should be explicitly identified, either:
    - **EA2.2a** by using an appropriate class system, or
    - **EA2.2b** through setting an `attribute` on a table, `x`, of `attr(x,
      "index") <- <index_col_name>`.

For EDA software which either implements custom classes or explicitly sets
attributes specifying index columns, these attributes should be used as the
basis of all table join operations, and in particular:

- **EA2.3** Table join operations should *not* be based on any assumed variable or
  column names

**Multi-tabular input**

EDA software designed to accept multi-tabular input should:

- **EA2.4** Use and demand an explicit class system for such input (for example,
  via the [`DM` package](https://github.com/krlmlr/dm)).
- **EA2.5** Ensure all individual tables follow the above standards for *Index Columns*


**Classes and Sub-Classes**

*Classes* are understood here to be the classes define single input objects,
while *Sub-Classes* refer to the class definitions of components of input
objects (for example, of columns of an input `data.frame`). EDA software which
is intended to receive input in general vector formats (see *Uni-variate Input*
section of *General Standards*) should ensure:

- **EA2.6** Routines appropriately process vector input of custom classes,
  including those which do not inherit from the `vector` class
- **EA2.7** Routines should appropriately process vector data regardless of
  additional attributes

The following code illustrates some ways by which "metadata" defining classes
and additional attributes associated with a standard vector object may by
modified.

``` r
x <- 1:10
class (x) <- "notvector"
attr (x, "extra_attribute") <- "another attribute"
attr (x, "vector attribute") <- runif (5)
attributes (x)
#> $class
#> [1] "notvector"
#> 
#> $extra_attribute
#> [1] "another attribute"
#> 
#> $`vector attribute`
#> [1] 0.03521663 0.49418081 0.60129563 0.75804346 0.16073301
```

All statistical software should appropriately deal with such input
data, as exemplified by the `storage.mode()`, `length()`, and `sum()` functions
of the `base` package, which return the appropriate values regardless of
redefinition of class or additional attributes.

``` r
storage.mode (x)
#> [1] "integer"
length (x)
#> [1] 10
sum (x)
#> [1] 55
storage.mode (sum (x))
#> [1] "integer"
```

Rectangular inputs in `data.frame` class may contain columns which are
themselves defined by custom classes, and which possess additional attributes.
EDA Software which accepts rectangular inputs should accordingly ensure:

- **EA2.8** EDA routines appropriately process rectangular input of custom classes,
  ideally by means of a single pre-processing routine which converts
  rectangular input to some standard form subsequently passed to all analytic
  routines.
- **EA2.9** EDA routines accept and appropriately process rectangular input in
  which individual columns may be of custom sub-classes including additional
  attributes.


#### Analytic Algorithms

(There are no specific standards for analytic algorithms in EDA Software.)

#### Return Results / Output Data

- **EA4.0** EDA Software should ensure all return results have types which are
  consistent with input types. For example, `sum`, `min`, or `max` values
  applied to `integer`-type vectors should return `integer` values, while
  `mean` or `var` will generally return `numeric` types.
- **EA4.1** EDA Software should implement parameters to enable explicit control
  of numeric precision
- **EA4.2** The primary routines of EDA Software should return objects for which
  default `print` and `plot` methods give sensible results. Default `summary`
  methods may also be implemented.


#### Visualization and Summary Output

Visualization commonly represents one of the primary functions of EDA Software,
and thus visualization output is given greater consideration in this category
than in other categories in which visualization may nevertheless play an
important role. In particular, one component of this sub-category is *Summary
Output*, taken to refer to all forms of screen-based output beyond conventional
graphical output, including tabular and other text-based forms. Standards for
visualization itself are considered in the two primary sub-categories of static
and dynamic visualization, where the latter includes interactive visualization.

Prior to these individual sub-categories, we consider a few standards
applicable to visualization in general, whether static or dynamic.

- **EA5.0** Graphical presentation in EDA software should be as accessible as
  possible or practicable. In particular, EDA software should consider
  accessibility in terms of:
    - **EA5.0a** Typeface sizes should default to sizes which explicitly enhance
      accessibility
    - **EA5.0b** Default colour schemes should be carefully constructed to ensure
      accessibility.
- **EA5.1** Any explicit specifications of typefaces which override default values
  should consider accessibility

**Summary and Screen-based Output**

- **EA5.2** Screen-based output should never rely on default print formatting of
  `numeric` types, rather should also use some version of `round(., digits)`,
  `formatC`, `sprintf`, or similar functions for numeric formatting according
  the parameter described in EDA4.2.
- **EA5.3** Column-based summary statistics should always indicate the
  `storage.mode`, `class`, or equivalent defining attribute of each column (as,
  for example, implemented in the default `print.tibble` method).

**General Standards for Visualization (Static and Dynamic)**

- **EA5.4** All visualisations should include units on all axes, with sensibly
  rounded values (for example, as produced by the `pretty()` function).

**Dynamic Visualization**

Dynamic visualization routines are commonly implemented as interfaces to
`javascript` routines. Unless routines have been explicitly developed as an
internal part of an R package, standards shall not be considered to apply to
the code itself, rather only to decisions present as user-controlled parameters
exposed within the R environment. That said, one standard may nevertheless be
applied, with an aim to minimise 

- **EA5.5** Any packages which internally bundle libraries used for dynamic
  visualization and which are also bundled in other, pre-existing R packages,
  should explain the necessity and advantage of re-bundling that library.


### Time Series Analyses {#standards-category-time}

Time series software is presumed to perform one or more of the following steps:

1. Accept and validate input data
2. Apply data transformation and pre-processing steps
3. Apply one or more analytic algorithms
4. Return the result of that algorithmic application
5. Offer additional functionality such as printing or summarising return results

This document details standards for each of these steps, each prefixed with "TS".

#### Input data structures and validation

Input validation is an important software task, and an important part of our
standards. While there are many ways to approach validation, the class systems
of R offer a particularly convenient and effective means. For Time Series
Software in particular, a range of class systems have been developed, for which
we refer to the section "Time Series Classes" in the CRAN Task view on [Time
Series Analysis"](https://cran.r-project.org/web/views/TimeSeries.html), and
the class-conversion package [`tsbox`](https://www.tsbox.help/). Software which
uses and relies on defined classes can often validate input through affirming
appropriate class(es). Software which does not use or rely on class systems
will generally need specific routines to validate input data structures. In
particular, because of the long history of time series software in R, and the
variety of class systems for representing time series data, new time series
package should accept as many different classes of input as possible by
according with the following standards:

- **TS1.0** Time Series Software should explicitly document the types and classes
  of input data able to be passed to each function.
- **TS1.1** Time Series Software should accept input data in as many time series
  specific classes as possible.
- **TS1.2** Time Series Software should implement validation routines to confirm
  that inputs are of acceptable classes (or represented in otherwise
  appropriate ways for software which does not use class systems).
- **TS1.3** Time Series Software should implement a single pre-processing routine
  to validate input data, and to appropriately transform it to a single uniform
  type to be passed to all subsequent data-processing functions (the [`tsbox`
  package](https://www.tsbox.help/) provides one convenient approach for this).
- **TS1.4** The pre-processing function described above should maintain all time-
  or date-based components or attributes of input data.

For Time Series Software which relies on or implements custom classes or types
for representing time-series data, the following standards should be adhered
to:

- **TS1.5** The software should ensure strict ordering of the time, frequency, or
  equivalent ordering index variable.
- **TS1.6** Any violations of ordering should be caught in the pre-processing stages
  of all functions.


**Time Intervals and Relative Time**

While most common packages and classes for time series data assume *absolute*
temporal scales such as those represented in [`POSIX`
classes](https://stat.ethz.ch/R-manual/R-devel/library/base/html/as.POSIXlt.html)
for dates or times, time series may also be quantified on *relative* scales
where the temporal index variable quantifies intervals rather than absolute
times or dates. Many analytic routines which accept time series inputs in
absolute form are also appropriately applied to analogous data in relative
form, and thus many packages should accept time series inputs both in absolute
and relative forms. Software which can or should accept times series inputs in
relative form should:

- **TS1.7** Accept inputs defined via the [`units`
  package](https://github.com/r-quantities/units/) for attributing SI units to
  R vectors.
- **TS1.8** Where time intervals or periods may be days or months, be explicit
  about the system used to represent such, particularly regarding whether a
  calendar system is used, or whether a year is presumed to have 365 days,
  365.2422 days, or some other value.


#### Pre-processing and Variable Transformation

**Missing Data**

One critical pre-processing step for Time Series Software is the appropriate
handling of missing data. It is convenient to distinguish between *implicit*
and *explicit* missing data. For regular time series, explicit missing data may
be represented by `NA` values, while for irregular time series, implicit
missing data may be represented by missing rows. The difference is demonstrated
in the following table.

<table>
<caption>Missing Values</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Time</td>
<td style="text-align: left;">value</td>
</tr>
<tr class="even">
<td style="text-align: left;">08:43</td>
<td style="text-align: left;">0.71</td>
</tr>
<tr class="odd">
<td style="text-align: left;">08:44</td>
<td style="text-align: left;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: left;">08:45</td>
<td style="text-align: left;">0.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">08:47</td>
<td style="text-align: left;">0.34</td>
</tr>
<tr class="odd">
<td style="text-align: left;">08:48</td>
<td style="text-align: left;">0.07</td>
</tr>
</tbody>
</table>

The value for 08:46 is *implicitly missing*, while the value for 08:44 is
*explicitly missing*. These two forms of missingness may connote different
things, and may require different forms of pre-processing. With this in mind,
the following standards apply:

- **TS2.0** Appropriate checks for missing data, and associated transformation
  routines, should be performed as part of initial pre-processing prior to
  passing data to analytic algorithms.
- **TS2.1** Time Series Software which presumes or requires regular data should
  only allow *explicit* missing values, and should issue appropriate diagnostic
  messages, potentially including errors, in response to any *implicit* missing
  values.
- **TS2.2** Where possible, all functions should provide options for users to
  specify how to handle missing data, with options minimally including:
  - **TS2.2a** error on missing data.
  - **TS2.2b** warn or ignore missing data, and proceed to analyse *irregular*
    data, ensuring that results from function calls with regular yet missing
    data return identical values to submitting equivalent irregular data with
    no missing values.
  - **TS2.2c** replace missing data with appropriately imputed values.
- **TS2.3** Functions should never assume non-missingness, and should never pass
  data with potential missing values to any base routines with default `na.rm =
  FALSE`-type parameters (such as
  [`mean()`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/mean.html),
  [`sd()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/sd.html) or
  [`var()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cor.html)).


**Stationarity**

Time Series Software should explicitly document assumptions or requirements
made with respect to the stationarity or otherwise of all input data. In
particular, any (sub-)functions which assume or rely on stationarity should:

- **TS2.4** Consider stationarity of all relevant moments - typically first (mean)
  and second (variance) order, or otherwise document why such
  consideration may be restricted to lower orders only.
- **TS2.5** Explicitly document all assumptions and/or requirements of stationarity
- **TS2.6** Implement appropriate checks for all relevant forms of stationarity,
  and either:
    - **TS2.6a** issue diagnostic messages or warnings; or
    - **TS2.6b** enable or advise on appropriate transformations to ensure
      stationarity.

The two options in the last point (TS2.6b) respectively translate to *enabling*
transformations to ensure stationarity by providing appropriate routines,
generally triggered by some function parameter, or *advising* on appropriate
transformations, for example by directing users to additional functions able to
implement appropriate transformations.


**Covariance Matrices**

Where covariance matrices are constructed or otherwise used within or as input
to functions, they should:

- **TS2.7** Incorporate a system to ensure that both row and column orders follow
  the same ordering as the underlying time series data. This may, for example,
  be done by including the `index` attribute of the time series data as an
  attribute of the covariance matrix.
- **TS2.8** Where applicable, covariance matrices should also include specification
  of appropriate units.


#### Analytic Algorithms

Analytic algorithms are considered here to reflect the core analytic components
of Time Series Software. These may be many and varied, and we explicitly
consider only a small subset here.

**Forecasting**

Statistical software which implements forecasting routines should:

- **TS3.0** Provide tests to demonstrate at least one case in which errors widen
  appropriately with forecast horizon.
- **TS3.1** If possible, provide at least one test which violates TS3.0
- **TS3.2** Document the general drivers of forecast errors or horizons, as
  demonstrated via the particular cases of TS3.0 and TS3.1
- **TS3.3** Either:
    - **TS3.3a** Document, preferable via an example, how to trim forecast values
      based on a specified error margin or equivalent; or
    - **TS3.3b** Provide an explicit mechanism to trim forecast values to a
      specified error margin, either via an explicit post-processing function,
      or via an input parameter to a primary analytic function.


#### Return Results

For (functions within) Time Series Software which return time series data:

- **TS4.0** Return values should either:
    - **TS4.0a** Be in same class as input data, for example by using the 
        [`tsbox` package](https://www.tsbox.help/) to re-convert from standard
        internal format (see 1.4, above); or
    - **TS4.0b** Be in a unique, preferably class-defined, format.
- **TS4.1** Any units included as attributes of input data should also be included
  within return values.
- **TS4.2** The type and class of all return values should be explicitly documented.

For (functions within) Time Series Software which return data other than direct
series:

- **TS4.3** Return values should explicitly include all appropriate units and/or
  time scales


**Data Transformation**

Time Series Software which internally implements routines for transforming data
to achieve stationarity and which returns forecast values should:

- **TS4.4** Document the effect of any such transformations on forecast data,
  including potential effects on both first- and second-order estimates.
- **TS4.5** In decreasing order of preference, either:
    - **TS4.5a** Provide explicit routines or options to back-transform data
      commensurate with original, non-stationary input data
    - **TS4.5b** Demonstrate how data may be back-transformed to a form
      commensurate with original, non-stationary input data.
    - **TS4.5c** Document associated limitations on forecast values


**Forecasting**

Where Time Series Software implements or otherwise enables forecasting
abilities, it should return one of the following three kinds of information.
These are presented in decreasing order of preference, such that software
should strive to return the first kind of object, failing that the second, and
only the third as a last resort.

- **TS4.6** Time Series Software which implements or otherwise enables forecasting
  should return either:
    - **TS4.6a** A distribution object, for example via one of the many packages
      described in the CRAN Task View on [*Probability
      Distributions*](https://cran.r-project.org/web/views/Distributions.html)
      (or the new [`distributional`
      package](https://pkg.mitchelloharawild.com/distributional/) as used in
      the [`fable` package](https://fable.tidyverts.org) for time-series
      forecasting).
    - **TS4.6b** For each variable to be forecast, predicted values equivalent to
      first- and second-order moments (for example, mean and standard error
      values).
    - **TS4.6c** Some more general indication of error involved with forecast
      estimates.
      
Beyond these particular standards for return objects, Time Series Software
which implements or otherwise enables forecasting should:

- **TS4.7** Ensure that forecast (modelled) values are clearly distinguished from
  observed (model or input) values, either (in this case in no order of
  preference) by
    - **TS4.7a** Returning forecast values alone
    - **TS4.7b** Returning distinct list items for model and forecast values
    - **TS4.7c** Combining model and forecast values into a single return object
      with an appropriate additional column clearly distinguishing the two
      kinds of data.


#### Visualization

Time Series Software should:

- **TS5.0** Implement default `plot` methods for any implemented class system.
- **TS5.1** When representing results in temporal domain(s), ensure that one axis
  is clearly labelled "time" (or equivalent), with continuous units.
- **TS5.2** Default to placing the "time" (or equivalent) variable on the
  horizontal axis.
- **TS5.3** Ensure that units of the time, frequency, or index variable are printed
  by default on the axis.
- **TS5.4** For frequency visualization, abscissa spanning $[-\pi, \pi]$ should be
  avoided in favour positive units of $[0, 2\pi]$ or $[0, 0.5]$, in all cases
  with appropriate additional explanation of units.
- **TS5.5** Provide options to determine whether plots of data with missing values
  should generate continuous or broken lines.

For the results of forecast operations, Time Series Software should

- **TS5.6** By default indicate distributional limits of forecast on plot
- **TS5.7** By default include model (input) values in plot, as well as forecast
  (output) values
- **TS5.8** By default provide clear visual distinction between model (input)
  values and forecast (output) values.


