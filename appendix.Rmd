# (APPENDIX) Appendix {-}

# Appendices

## Notes on Scope and the Python Statistical Ecosystem {#python}

```{r startup-appendix, echo = FALSE, message = FALSE}
library(dplyr)
library(ggplot2)
library(rvest)
library(igraph)
theme_set(theme_minimal())
```

Two factors may be usefully noted in this regard:

```{r pypi-projects, echo = FALSE}
u <- "https://pypi.org/"
x <- read_html(u) %>%
  # html_nodes ("div.statistics-bar") %>%
  html_nodes("p.statistics-bar__statistic") %>%
  html_text()
pypi_n_projects <- x [grep("projects", x)] %>%
  gsub("projects|[[:space:]]", "", .)

cran_n_projects <- format(nrow(available.packages()), big.mark = ",")

pypi_cran_ratio <- floor(as.integer(gsub(",", "", pypi_n_projects)) /
  as.integer(gsub(",", "", cran_n_projects)))
```

1. The potential number of python packages for statistical analyses is likely
   to be relatively more restricted than relative numbers of **R** packages.
   Taking as indicative presentations at the previous three Joint Statistical
   Meetings (JSMs; 2018-2020), no python packages were referred to in any
   abstract, while 32 **R** packages were presented, along with two
   meta-platforms for **R** packages. Presentations at the Symposium of Data
   Science and Statistics (SDSS) for 2018-19 similarly including numerous
   presentations of **R** packages, along with presentation of
   [three](https://altair-viz.github.io)
   [python](https://github.com/ajboyd2/salmon)
   [packages](https://github.com/dlsun/symbulate). It may accordingly be
   expected that potential expansion to include python packages will demand
   relatively very little time or effort compared with that devoted to **R**
   packages as the primary software scope.
2. In spite of the above, the community of python users is enormously greater,
   reflected in the currently `r pypi_n_projects` packages compared with
   `r cran_n_projects` packages on CRAN, or over `r pypi_cran_ratio` times as
   many python packages. Similarly, 41.7% of all respondents to the [2019
   stackoverflow developer
   survey](https://insights.stackoverflow.com/survey/2019) nominated python as
   their most popular language, compared with only 5.8% who nominated **R**.

The relative importance of python is powerfully reflected in temporal trends
from the [stackoverflow developer
survey](https://insights.stackoverflow.com/survey/2019) from the previous three
years, with results shown in the following graphic.

```{r py_v_r, echo = FALSE, message = FALSE}
year <- 2017:2019
python_used <- c(31.7, 38.8, 41.7)
r_used <- c(4.4, 6.1, 5.8)
python_loved <- c(62.7, 68.0, 73.1)
r_loved <- c(49.9, 49.4, 51.7)

dat <- rbind(
  tibble(
    year = year,
    proportion = python_used,
    language = "python-used",
    context = "used"
  ),
  tibble(
    year = year,
    proportion = r_used,
    language = "R-used",
    context = "used"
  ),
  tibble(
    year = year,
    proportion = python_loved,
    language = "python-loved",
    context = "loved"
  ),
  tibble(
    year = year,
    proportion = r_loved,
    language = "R-loved",
    context = "loved"
  )
)

ggplot(dat, aes(x = year, y = proportion, color = language)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = year)
```

Python is not only more used and more loved than **R**, but both statistics for
python have consistently grown at a faster rate over the past three years as
have equivalent statistics for **R**.

Both languages nevertheless have relative well-defined standards for software
packaging, python via the [Python Package Index
(pypi)](https://packaging.python.org/tutorials/packaging-projects), and **R**
via [CRAN](https://cran.r-project.org). In contrast to CRAN, which runs its own
checks on all packages on a daily basis, there are no automatic checks for
[pypi](https://packaging.python.org/tutorials/packaging-projects) packages, and
almost any form of package that minimally conforms to the standards may be
submitted. This much lower effective barrier to entry likely partially
contributes to the far greater numbers of
[pypi](https://packaging.python.org/tutorials/packaging-projects) 
(`r pypi_n_projects`) than
[CRAN](https://cran.r-project.org) (`r cran_n_projects`) packages.


## Empirical Derivation of Categories

We attempted to derive a realistic categorisation through using empirical data
from several sources of potential software submissions, including all
apparently "statistical" R packages published in the [Journal of Open Source
Software (JOSS](https://joss.theoj.org)), packages published in the [Journal of
Statistical Software](https://www.jstatsoft.org/index), software presented at
the 2018 and 2019 Joint Statistical Meetings (JSM), and Symposia on Data
Science and Statistics (SDSS), well as CRAN task views. We have also compiled
a list of the descriptions of [all packages rejected by
rOpenSci](https://github.com/mpadge/statistical-software/blob/master/abstracts/ropensci-abstracts.md)
as being out of current scope because of current inability to consider
statistical packages, along with a selection of [recent statistical
R packages](https://github.com/mpadge/statistical-software/blob/master/abstracts/joss-abstracts.md)
accepted by JOSS. (The full list of all R package published by JOSS can be
viewed at <https://joss.theoj.org/papers//in/R>).

We allocated one or more key words (or phrases) to each abstract, and use the
frequencies and inter-connections between these to inform the following
categorisation are represented in the [interactive
graphic](https://ropenscilabs.github.io/statistical-software/abstracts/network-terms/index.html)
(also included in the [Appendix](#appendix-keywords)), itself derived from
analyses of abstracts from all statistical software submitted to both rOpenSci
and JOSS. (Several additional analyses and graphical representations of these
raw data are included an [auxiliary github
repository](https://github.com/ropenscilabs/statistical-software).) The primary
nodes that emerge from these empirical analyses (with associated *relative*
sizes in parentheses) are shown in the following table.

```{r top-10terms, message = FALSE}
x <- readLines("scripts/joss-abstracts/categories.Rmd")
x <- x [grep("[0-9]*\\. \\[", x)]
names <- vapply(x, function(i) {
  res <- strsplit(i, "\\[\\`") [[1]]
  strsplit(res, "\\`\\]") [[2]] [1]
},
character(1),
USE.NAMES = FALSE
)
terms <- lapply(x, function(i) {
  res <- strsplit(i, ":\\s") [[1]] [2]
  res <- strsplit(res, ";\\s") [[1]] [1] # rm "; input"
  strsplit(res, ",\\s") [[1]]
})
input <- lapply(x, function(i) {
  res <- strsplit(i, "input: ") [[1]] [2]
  res <- strsplit(res, ";\\s") [[1]] [1]
  if (grepl(",\\s", res)) {
    res <- strsplit(res, ",\\s") [[1]]
  }
  return(res)
})
output <- lapply(x, function(i) {
  res <- strsplit(i, "output: ") [[1]] [2]
  if (grepl(",\\s", res)) {
    res <- strsplit(res, ",\\s") [[1]]
  }
  return(res)
})
names(terms) <- names(input) <- names(output) <- names
n_abstracts <- length(terms)
terms0 <- terms # used below

terms <- unlist(terms) %>%
  table() %>%
  sort(decreasing = TRUE)
terms <- data.frame(
  n = seq_along(terms),
  term = names(terms),
  proportion = as.integer(terms) / n_abstracts,
  stringsAsFactors = FALSE
)
terms$term [terms$term == "scores"] <- "statistical indices and scores"
n <- max(which(terms$proportion > 0.05))
cp <- paste0 ("Most frequent key words from all JOSS abstracts (N = 92) ",
              "for statistical software. Proportions are scaled *per ",
              "abstract*, with each abstract generally having multiple ",
              "key words, and so sum of proportions exceeds one.")
knitr::kable(head(terms, n = n), digits = c(0, NA, 3), caption = cp)
```

```{r collate-some-categories}
terms$term [terms$term %in% c("Bayesian", "Monte Carlo")] <-
    "Bayesian & Monte Carlo"
terms$term [terms$term %in% c("dimensionality reduction",
                              "feature selection")] <-
    "dimensionality reduction & feature selection"
terms$term [terms$term %in% c("regression", "splines", "interpolation")] <-
    "regression/splines/interpolation"
terms$term [terms$term == "EDA"] <- "Exploratory Data Analysis (EDA)"
terms <- terms %>%
  group_by(term) %>%
  summarise(proportion = sum(proportion)) %>%
  arrange(by = desc(proportion))
```


The top key words and their inter-relationships within the main [network
diagram](https://ropenscilabs.github.io/statistical-software/abstracts/network-terms/index.html)
were used to distinguish the following primary categories representing all
terms which appear in over 5% of all abstracts, along with the two additional
categories of "spatial" and "education". We have excluded the key word
"Estimates" as being too generic to usefully inform standards, and have also
collected a few strongly-connected terms into single categories.

```{r collate-methods-categories}
out <- data.frame(terms [which(terms$proportion > 0.05), ])
out <- out [which(!out$term == "estimates"), ]
out <- rbind(
  out, terms [which(terms$term == "spatial"), ],
  terms [which(terms$term == "education"), ]
)
out$comment <- ""
out$comment [out$term == "dimensionality reduction & feature selection"] <-
  "Commonly as a result of ML algorithms"
out$comment [out$term == "regression/splines/interpolation"] <-
  "Including function data analysis"
out$comment [out$term == "probability distributions"] <-
  paste0 ("Including kernel densities, likelihood estimates and estimators, ",
          "and sampling routines")
out$comment [out$term == "categorical variables"] <-
  paste0 ("Including latent variables, and those output from ML algorithms. ",
          "Note also that method for dimensionality reduction (such as ",
          "clustering) often transform data to categorical forms.")
out$comment [out$term == "Exploratory Data Analysis (EDA)"] <-
  paste0 ("Including information statistics such as Akaike's criterion, ",
          "and techniques such as random forests. ",
          "Often related to workflow software.")
out$comment [out$term == "survival"] <-
  paste0 ("strongly related to EDA, yet differing in being strictly ",
          "descriptive of software *outputs* whereas EDA may include ",
          "routines to explore data *inputs* and other pre-output ",
          "stages of analysis.")
out$comment [out$term == "summary statistics"] <-
  paste0 ("Primarily related in the empirical data to regression and ",
          "survival analyses, yet clearly a distinct category of its own.")
out$comment [out$term == "workflow"] <-
    "Often related to EDA, and very commonly also to ML."
out$comment [out$term == "model selection"] <-
  paste0 ("A important intermediate node between such categories as ML, ",
          "Bayesian and Monte Carlo techniques, visualisation, and EDA.")
out$comment [out$term == "statistical indices and scores"] <-
  paste0 ("Software generally intended to produce specific ",
          "indices or scores as statistical output")
out$comment [out$term == "spatial"] <-
  paste0 ("Also an important intermediate node connecting several ",
          "other nodes, yet defining its own distinct cluster ",
          "reflecting a distinct area of expertise.")

out <- data.frame(
  n = seq(nrow(out)),
  term = out$term,
  proprtion = out$proportion,
  comment = out$comment,
  stringsAsFactors = FALSE
)

cp <- paste0 ("Proposed categorisation of statistical software, ",
              "with corresponding proportions of all JOSS software ",
              "matching each category")
knitr::kable(out, digits = c(0, NA, 3, NA), caption = cp)
```


The full network diagram can then be reduced down to these categories only,
with interconnections weighted by all first- and second-order interconnections
between intermediate categories, to give the following, simplified diagram
(in which "scores" denotes "statistical indices and scores"; with the diagram
best inspected by dragging individual nodes to see their connections to
others).

```{r visnetwork-simple}
nodes <- table(unlist(terms0))
nodes <- data.frame(
  id = names(nodes),
  label = names(nodes),
  value = as.integer(nodes),
  stringsAsFactors = FALSE
)
edges <- lapply(terms0, function(i) {
  if (length(i) > 1) {
    res <- sort(i)
    n <- combn(seq_along(res), 2)
    cbind(
      res [n [1, ]],
      res [n [2, ]]
    )
  }
})
edges <- do.call(rbind, edges)
edges <- data.frame(
  from = edges [, 1],
  to = edges [, 2],
  stringsAsFactors = FALSE
) %>%
  group_by(from, to) %>%
  summarise(width = length(from)) %>%
  ungroup()
# Remove isolated edges:
# annotation, areal weights, binomial distribution, cubature, gene loci,
# generalized least squares, misspecification, classification, interpolation,
# over-dispersion, integration, random effects, probit model
cl <- graph_from_data_frame(edges) %>%
  clusters()
out <- names(cl$membership [which(cl$membership != which.max(cl$csize))])
nodes <- nodes [which(!nodes$id %in% out), ]
edges <- edges [which(!(edges$from %in% out | edges$to %in% out)), ]

# manually agglomerate some categories
from <- c(
  "Bayesian|Monte Carlo", "dimensionality reduction|feature selection",
  "^regression|splines|interpolation"
)
to <- c("Bayes/MC", "dimensionality reduction", "regression")
for (i in seq_along(from)) {
  edges$from [grep(from [i], edges$from)] <- to [i]
  edges$to [grep(from [i], edges$to)] <- to [i]
  nodes$id [grep(from [i], nodes$label)] <- to [i]
  nodes$label [grep(from [i], nodes$label)] <- to [i]
}
edges <- edges %>%
  group_by(from, to) %>%
  summarise(width = sum(width)) %>%
  ungroup()
nodes <- nodes %>%
  group_by(label) %>%
  summarise(value = sum(value)) %>%
  transform(id = label)

g <- graph_from_data_frame(edges)
dg <- distances(g)

# add to edge distances all intermediate distances between O(2) connections
edges2 <- edges
dgnames <- rownames(dg)
for (i in seq(nrow(edges2))) {
  dgfrom <- match(edges2$from [i], rownames(dg))
  dgto <- match(edges$to [i], colnames(dg))
  nbs_from <- dgnames [which(dg [dgfrom, ] < 3)]
  nbs_to <- dgnames [which(dg [, dgto] < 3)]
  nbs <- intersect(nbs_from, nbs_to)
  index <- which(edges$from == edges$from [i] & edges$to %in% nbs)
  edges2$width [i] <- sum(edges$width [index])
}

ns <- nodes [order(nodes$value, decreasing = TRUE), ]
index <- c(
  which(!grepl("estimates", ns$label [1:15])),
  grep("spatial|education", ns$label)
)
ns <- ns [index, ]
es <- edges2 [which(edges$from %in% ns$label & edges$to %in% ns$label), ]
# es <- es [which (es$from %in% ns$label & es$to %in% ns$label), ]
es <- es [which(!es$from == es$to), ]
es$width <- es$width * 5 / max(es$width)
library(visNetwork)
visNetwork(ns, es)
```

Standards considered under any of the ensuing categories must be developed with
reference to inter-relationships between categories, and in particular to
potential ambiguity within and between any categorisation. An example of such
ambiguity, and of potential difficulties associated with categorisation, is the
category of "network" software which appropriate describes the
[`grapherator`](https://github.com/jakobbossek/grapherator) package (with
accompanying [JOSS paper](https://joss.theoj.org/papers/10.21105/joss.00528))
which is effectively a distribution generator for data represented in
a particular format that happens to represent a graph; and three JSM
presentations, one on [network-based clustering of high-dimensional
data](https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=327171),
one on [community structure in dynamic
networks](https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=328764)
and one on [Gaussian graphical
models](https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=328764).
Standards derived for network software must accommodate such diversity of
applications, and must accommodate software for which the "network" category
may pertain only to some relatively minor aspect, while the primary algorithms
or routines may not be related to network software in any direct way.


## Analysis of statistical software keywords {#appendix-keywords}

The
[JOSS](https://joss.theoj.org)
conducts its own peer review process, and publishes textual descriptions of
accepted software. Each piece of software then has its own web page on the
journal's site, on which the text is presented as a compiled `.pdf`-format
document, along with links to the open review, as well as to the software
repository. The published document must be included within the software
repository in a file named `paper.md`, which enables automatic extraction and
analysis of these text descriptions of software. Rather than attempt
a comprehensive, and unavoidably subjective, categorization of software, these
textual descriptions were used to identify key words or phrases (hereafter,
"keywords") which encapsulated the purpose, function, or other general
descriptive elements of each piece of software. Each paper generally yielded
multiple keywords. Extracting these from all papers judged to be potentially in
scope allowed for the construction of a network of topics, in which the nodes
were the key words and phrases, and the connections between any pair of nodes
reflected the number of times those two keywords co-occurred across all papers.

We extracted all papers accepted and published by JOSS (217 at the time of
writing in early 2020), and manually determined which of these were broadly
statistical, reducing the total to 92. We then read through the contents of
each of these, and recorded as many keywords as possible for each paper. The
resultant network is shown in the following interactive graphic, in which nodes
are scaled by numbers of occurrences, and edges by numbers of co-occurrences.
(Or [click
here](https://ropenscilabs.github.io/statistical-software/abstracts/network-terms/index.html)
for full-screen version with link to code.)

```{r visNetwork, message = FALSE}
x <- readLines("stat-software-categories.md")
x <- x [grep("[0-9]*\\. \\[", x)]
names <- vapply(x, function(i) {
  res <- strsplit(i, "\\[\\`") [[1]]
  strsplit(res, "\\`\\]") [[2]] [1]
},
character(1),
USE.NAMES = FALSE
)
terms <- lapply(x, function(i) {
  res <- strsplit(i, ":\\s") [[1]] [2]
  res <- strsplit(res, ";\\s") [[1]] [1] # rm "; input"
  strsplit(res, ",\\s") [[1]]
})
input <- lapply(x, function(i) {
  res <- strsplit(i, "input: ") [[1]] [2]
  res <- strsplit(res, ";\\s") [[1]] [1]
  if (grepl(",\\s", res)) {
    res <- strsplit(res, ",\\s") [[1]]
  }
  return(res)
})
output <- lapply(x, function(i) {
  res <- strsplit(i, "output: ") [[1]] [2]
  if (grepl(",\\s", res)) {
    res <- strsplit(res, ",\\s") [[1]]
  }
  return(res)
})
names(terms) <- names(input) <- names(output) <- names

# Then convert to `visNetwork` nodes and edges tables:
nodes <- table(unlist(terms))
nodes <- data.frame(
  id = names(nodes),
  label = names(nodes),
  value = as.integer(nodes),
  stringsAsFactors = FALSE
)
edges <- lapply(terms, function(i) {
  if (length(i) > 1) {
    res <- sort(i)
    n <- combn(seq_along(res), 2)
    cbind(res [n [1, ]], res [n [2, ]])
  }
})
edges <- do.call(rbind, edges)
edges <- data.frame(
  from = edges [, 1],
  to = edges [, 2],
  stringsAsFactors = FALSE
) %>%
  group_by(from, to) %>%
  summarise(width = length(from)) # Remove isolated edges:
# annotation, areal weights, binomial distribution, cubature, gene loci,
# generalized least squares, misspecification, classification, interpolation,
# over-dispersion, integration, random effects, probit model
cl <- graph_from_data_frame(edges) %>%
  clusters()
out <- names(cl$membership [which(cl$membership != which.max(cl$csize))])
nodes <- nodes [which(!nodes$id %in% out), ]
edges <- edges [which(!(edges$from %in% out | edges$to %in% out)), ]

library(visNetwork)
visNetwork(nodes, edges)
```

Such a network visualization enables immediate identification of more and less
central concepts including, in our case, several that we may not otherwise have
conceived of as having been potentially in scope. We then used this network to
define our set of key "in scope" concepts. This figure also reveals that many
of these keywords are somewhat "lower level" than the kinds of concepts we
might otherwise have used to define scoping categories. For example, keywords
such as "likelihood" or "probability" are not likely to be useful in defining
actual categories of statistical software, yet they turned out to lie at the
centres of relatively well-defined groups of related keywords.

We also examined the forms of both input and output data for each of the 92
pieces of software described in these JOSS papers, and constructed [an
additional
graph](https://ropenscilabs.github.io/statistical-software/abstracts/network-io/index.html)
directionally relating these different data formats.

```{r io-nodes-edges}
terms <- table(c(unlist(input), unlist(output)))
nodes <- data.frame(
  id = seq_along(terms),
  label = names(terms),
  value = as.integer(terms),
  stringsAsFactors = FALSE
)
edges <- list()
for (i in seq_along(input)) {
  edges [[i]] <- expand.grid(input [[i]], output [[i]])
}
edges <- do.call(rbind, edges) %>%
  data.frame(
    from = .$Var1,
    to = .$Var2
  ) %>%
  group_by(from, to) %>%
  summarise(width = length(from))
edges$from <- nodes$id [match(edges$from, nodes$label)]
edges$to <- nodes$id [match(edges$to, nodes$label)]
# remove isolated edges:
cl <- graph_from_data_frame(edges) %>%
  clusters()
out <- names(cl$membership [which(cl$membership != which.max(cl$csize))])
nodes <- nodes [which(!nodes$id %in% out), ]
edges <- edges [which(!(edges$from %in% out | edges$to %in% out)), ]

visNetwork(nodes, edges)
```

## Other Software Standards {#other-software-standards}


The following list represents the standards developed by the 
[Software Sustainability Institute](https://www.software.ac.uk/):

- 1. Usability
  - 1.1 Understandability
    - High level description of what/who the software is for
    - High level description of what the software does
    - High level description of how the software works
    - Design rationale - why the software does things the way it does
    - Architectural overview with diagrams
    - Descriptions of intended use cases
    - Case studies of use
  - 1.2 Documentation
    - Provides a high level overview of the software
    - Partitioned into sections for users, user-developers, and developers
      (depending on the software)
    - Lists resources for further information
    - Is task-oriented
    - Consists of clear, step-by-step instructions
    - Gives examples of what the user can see at each step
    - For problems and error messages, the symptoms and step-by-step solutions
      are provided
    - Does not use terms like "intuitive", "user-friendly", "easy to use",
      "simple", or "obviously" (other than in quotes from satisfied users).
    - States command names, syntax, parameters, error messages exactly as they
      appear or should be typed.
    - Uses ${\tt teletype-style fonts}$ for command line inputs and outputs,
      source code fragments, function names, class names, etc.
    - English language descriptions of commands or errors are provided.
    - Plain text files (e.g. READMEs) use indentation and underlining to
      structure the text.
    - Plain text files do not use `TAB` characters to indent the text.
    - Documentation is complete (includes configuration requirements or properties).
    - Is held under version control alongside the code
    - Is on the project web site
    - Documentation on web site makes it clear what version of software the
      documentation applies to.
  - 1.3 Buildability
    - Straightforward to meet build pre-requisites
    - Straightforward to build the software
    - Web site has build instructions
    - Source distributions have build instructions
    - Web site lists all third-party dependencies that are not bundled
    - Source distribution lists all third-party dependencies that are not
      bundled
    - All mandatory third-party dependencies are currently available
    - All optional third-party dependencies are currently available
  - 1.4 Installability
    - Web site has installation instructions
    - Binary distributions have installation instructions
    - Web site lists all third-party dependencies that are not bundled
  - 1.5 Learnability
    - A getting started guide is provided with a basic example
    - Instructions are provided for many basic use cases
    - Reference guides are provided for all options
    - Documentation is provided for user-developers and developers
  - 1.5 Performance
- 2. Sustainability &amp; Maintainability
  - 2.1 Identity
    - Identity of project is clear and unique both within domain of application
      and generally.
    - Project/software has own domain name
    - Project/software has distinct name within application area (appears
      within first page of search results when entered with domain keywords).
    - Project/software has distinct name regardless of application area
    - Project/software does not throw up embarrassing "Did you mean ..."
      suggestions on search engines.
    - Project/software name does not violate a trademark
    - Project/software name is trademarked
  - 2.2 Copyright
    - Web site states copyright
    - Web sites states developers and funders
    - If multiple web sites, then all state exactly same copyright, license,
      authorship
    - Each source code file has copyright statement
    - If supported by language, each source file has copyright statement
      embedded within a constant - 
    - Each source code file has a license header
  - 2.3 Licencing
    - Appropriate licence
    - Web site states licence
    - Software has a licence
    - Software has an open source licence
    - Software has an Open Software Institute recognised licence
  - 2.4 Governance
    - Management is transparent
    - Project has a defined governance policy
    - Governance policy is publicly available
  - 2.5 Community
    - To what extent does an active user community exist?
    - Web site has statement of numbers of users/developers/members
    - Web site has quotes from satisfied users
    - Web site lists most important partners or collaborators
    - Web site has list of project publications
    - Web site lists third-party publications that use the software
    - Web site lists software that uses/bundles this software
    - Users are required to cite software if publishing results derived from
      its use
    - Users exists who are not members of the project
    - Developers exists who are not members of the project
  - 2.6 Accessibility
    - To what extent is software accessible?
    - Binary distributions are available
    - Binary distributions are available without need for registration or
      authorisation
    - Source distributions are available
    - Source distributions are available without need for registration or
      authorisation
    - Access to source code repository is available (whether for free, payment,
      registration)
    - Anonymous read-only access to source code repository
    - Ability to browse source code repository online
    - Repository hosted in sustainable third-party site which will live beyond
      lifetime of any current funding
    - Downloads page shows evidence of regular releases
  - 2.7 Testability
    - Straightforward to test software to verify modifications
    - Project has unit tests
    - Project has integration tests
    - Project has scripts for testing non-automated scenarios (e.g. GUIs)
    - Project recommends tools to check conformance to coding standards
    - Project has automated tests to check conformance to coding standards
    - Project recommends tools to check test coverage
    - Project has automated tests to check test coverage
    - A minimum test coverage level has been defined
    - There is an automated test for this minimum level
    - Tests are automatically run nightly
    - Continuous integration is supported
    - Test results are visible to all developers/members
    - Test results are visible publicly
    - Project specifies how to set up external resources (FTP servers,
      databases, etc.) for tests
    - Tests create their own files, database tables, etc.
  - 2.8 Portability
    - To what extent can software be used on other platforms? (Checkboxes for
      various platforms.)
  - 2.9 Supportability
    - To what extent will software be supported currently and in the future?
    - Web site has page describing how to get support
    - User doc has page describing how to get support
    - Software describes how to get support (in README)
    - Project has an e-mail address
    - Project e-mail address has domain name
    - E-mails are read by more than one person
    - E-mails are archived
    - E-mails archives are publicly readable
    - E-mail archives are searchable
    - Project has a ticketing system
    - Ticketing system is publicly available
    - Ticketing system is searchable
    - Web site has a site map or index
    - Web site has a search facility
    - Project resources are hosted externally in a sustainable third-part
      repository which will live beyond lifetime of current project
    - E-mail archives or ticketing system shows that queries are resounded to
      (not necessarily fixed) within a week.
    - If there is a blog, it is regularly used
    - E-mail lists of forums, if present, have regular posts
  - 2.10 Analysability
    - Source code is structured into modules or packages
    - Source code structure relates clearly to the architecture or design.
    - Source code repository is in a version control system
    - Structure of source code repository and how this maps to software's
      components is documented
    - Source releases are snapshots of the repository
    - Source code is commented
    - Source code comments are written in a document generation mark-up
      language
    - Source code is laid out and indented well
    - Source code uses sensible class, package, and variable names
    - There are no old or obsolete source code files that should be handled by
      version control
    - There is no commented out code
    - There are not TODOs in the code
    - Auto-generated source code is in separate directories from other source
      code
    - Regeneration of auto-generated source code is documented
    - Coding standards are recommended by the project
    - Coding standards are required to be observed
    - Project-specific coding standards are consistent with community standards
  - 2.11 Changeability
    - Project has a defined contributions policy
    - Contributions policy is publicly available
    - Contributors retain copyright/IP of their contributions
    - Users, developer members, and developers who are not members can contribute
    - Project has a defined and stable deprecation policy
    - Stability/deprecation policy is publicly available
    - Releases document deprecated components within release
    - Releases document removed or changed components within release
  - 2.12 Evolvability
    - Web site describes project roadmap, plans, or milestones
    - Web site describes how project is funded or sustained
    - Web site describes end date of current funding lines
  - 2.13 Interoperability
    - Uses open standards
    - Uses mature, ratified, non-draft standards
    - Provides tests demonstrating compliance with standards

In contrast to these qualitative aspects, @mili_software_2015 identifies the
following attributes of *Software Quality*:

- 1. Functional Attributes
    - 1.1 Correctness
    - 1.2 Robustness
- 2. Useability Attributes
    - 2.1 Ease of Use
    - 2.2 Ease of Learning
    - 2.3 Customizability
    - 2.4 Calibrability
    - 2.5 Interoperability
- 3. Structural Attributes
    - 3.1 Design Integrity
    - 3.2 Modularity (including "cohesion" and "coupling")
    - 3.3 Testability
    - 3.4 Adaptability

Other aspects derived from other forms of standards include:

- Must use https
- Must be in English
- Unique version numbering
- Semantic versioning
- Release notes
- Static code analysis (with links to lots of language-specific tools)
- Dynamic code analysis (with links to lots of language-specific tools)
- Use of memory check tools, or memory-safe languages
- Functions that are [type
  stable](https://cran.r-project.org/web/packages/vctrs/vignettes/stability.html)
  unless explicitly indicated and explained otherwise. (See also the section on
  type stability in the [tidyverse design
  guide](https://principles.tidyverse.org/out-type-stability.html).)


## Bibliography
